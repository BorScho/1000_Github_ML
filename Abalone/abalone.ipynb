{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set Information: ###\n",
    "<br>\n",
    "Predicting the age of abalone from physical measurements. The age of abalone is determined by cutting the shell through the cone, staining it, and counting the number of <br>\n",
    "rings through a microscope -- a boring and time-consuming task. Other measurements, which are easier to obtain, are used to predict the age. Further information, such as <br>\n",
    "weather patterns and location (hence food availability) may be required to solve the problem.<br>\n",
    "<br>\n",
    "From the original data examples with missing values were removed (the majority having the predicted value missing), and the ranges of the continuous values have been <br>\n",
    "scaled for use with an ANN (by dividing by 200).<br>\n",
    "<br>\n",
    "<br>\n",
    "Attribute Information:<br>\n",
    "<br>\n",
    "Given is the attribute name, attribute type, the measurement unit and a brief description. The number of rings is the value to predict: either as a continuous value or as <br>\n",
    "a classification problem.<br>\n",
    "<br>\n",
    "Name / Data Type / Measurement Unit / Description<br>\n",
    "-----------------------------<br>\n",
    "Sex / nominal / -- / M, F, and I (infant)<br>\n",
    "Length / continuous / mm / Longest shell measurement<br>\n",
    "Diameter / continuous / mm / perpendicular to length<br>\n",
    "Height / continuous / mm / with meat in shell<br>\n",
    "Whole weight / continuous / grams / whole abalone<br>\n",
    "Shucked weight / continuous / grams / weight of meat<br>\n",
    "Viscera weight / continuous / grams / gut weight (after bleeding)<br>\n",
    "Shell weight / continuous / grams / after being dried<br>\n",
    "Rings / integer / -- / +1.5 gives the age in years<br>\n",
    "<br>\n",
    "The readme file contains attribute statistics.<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole</th>\n",
       "      <th>Shucked</th>\n",
       "      <th>Viscera</th>\n",
       "      <th>Shell</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Length  Diameter  Height   Whole  Shucked  Viscera  Shell  Rings\n",
       "0   M   0.455     0.365   0.095  0.5140   0.2245   0.1010  0.150     15\n",
       "1   M   0.350     0.265   0.090  0.2255   0.0995   0.0485  0.070      7\n",
       "2   F   0.530     0.420   0.135  0.6770   0.2565   0.1415  0.210      9\n",
       "3   M   0.440     0.365   0.125  0.5160   0.2155   0.1140  0.155     10\n",
       "4   I   0.330     0.255   0.080  0.2050   0.0895   0.0395  0.055      7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "columns = [\"Sex\", \"Length\", \"Diameter\", \"Height\", \"Whole\", \"Shucked\", \"Viscera\", \"Shell\", \"Rings\"]\n",
    "sourcepath= Path(\"D:/9999_Github_MachineLearning/ML_experiments/ML_experiments/Abalone/Data/abalone.data\")\n",
    "data = pd.read_csv(sourcepath, names=columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole</th>\n",
       "      <th>Shucked</th>\n",
       "      <th>Viscera</th>\n",
       "      <th>Shell</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height   Whole  Shucked  Viscera  Shell  Sex_F  Sex_I  \\\n",
       "0   0.455     0.365   0.095  0.5140   0.2245   0.1010  0.150      0      0   \n",
       "1   0.350     0.265   0.090  0.2255   0.0995   0.0485  0.070      0      0   \n",
       "2   0.530     0.420   0.135  0.6770   0.2565   0.1415  0.210      1      0   \n",
       "3   0.440     0.365   0.125  0.5160   0.2155   0.1140  0.155      0      0   \n",
       "4   0.330     0.255   0.080  0.2050   0.0895   0.0395  0.055      0      1   \n",
       "\n",
       "   Sex_M  \n",
       "0      1  \n",
       "1      1  \n",
       "2      0  \n",
       "3      1  \n",
       "4      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split off targets:\n",
    "targets = data.iloc[:,-1]\n",
    "data = data.iloc[:,:-1]\n",
    "\n",
    "# one-hot-encode Sex:\n",
    "data = pd.get_dummies(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_seed = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.to_numpy(), targets.to_numpy(), test_size= 0.2, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3341, 10), (836, 10), (3341,), (836,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spot-Shooting Algorithms ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.281\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "log_reg = Pipeline([\n",
    "    (\"ssc\", StandardScaler()),\n",
    "    (\"logreg\", LogisticRegression(tol= 0.2, max_iter=1000, random_state=random_seed)) \n",
    "])\n",
    "\n",
    "log_reg.fit(X_train, y_train)\n",
    "print(f\"{log_reg.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.548\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = Pipeline([\n",
    "    (\"ssc\", StandardScaler()),\n",
    "    (\"linreg\", LinearRegression())\n",
    "]) \n",
    "lin_reg.fit(X_train, y_train)\n",
    "print(f\"{lin_reg.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_reg = Pipeline([\n",
    "    (\"ssc\", StandardScaler()),\n",
    "    (\"sv_reg\", SVR())\n",
    "    ])\n",
    "\n",
    "svr_reg.fit(X_train, y_train)\n",
    "print(f\"{svr_reg.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.214\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_clf.fit(X_train, y_train)\n",
    "#tree_clf.predict(X_test, y_test)\n",
    "print(f\"{tree_clf.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(X_train, y_train)\n",
    "print(f\"{tree_reg.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum-Up Spot Shot: ##\n",
    "1. Linear Regression score: 0.548\n",
    "2. Support Vector Regression score: 0.536\n",
    "3. Logistic Regression score: 0.281\n",
    "4. Decision Tree Classification score: 0.214\n",
    "5. Decision Tree Regression score: 0.118\n",
    "<br>\n",
    "<br>\n",
    "So we will go with linear regression and support vector regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Results ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression on KMeans ###\n",
    "\n",
    "Clustering by KMeans reduces variance (and increases bias by los of information) for the lin-reg. If the number of clusters is to smal, the datapoints for the lin-reg become to coarse (high bias), if their number is to high there is increase in bias and to little loss in variance. So probably a grid-search for the number of clusters is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'kmeans__max_iter': 800, 'kmeans__n_clusters': 120}\n",
      "Best training-score: 0.556\n",
      "Score on test data: 0.562\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe_lin_reg = Pipeline([\n",
    "    (\"ssc\", StandardScaler()),\n",
    "    (\"kmeans\", KMeans()),\n",
    "    (\"lin_reg\", LinearRegression())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    \"kmeans__n_clusters\" : np.arange(10, 200, 10),\n",
    "    \"kmeans__max_iter\" : np.arange(500, 1000, 100),\n",
    "}\n",
    "clf = GridSearchCV(pipe_lin_reg, params, n_jobs=-1, cv=10)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {clf.best_params_}\")\n",
    "print(f\"Best training-score: {clf.best_score_:.3f}\")\n",
    "print(f\"Score on test data: {clf.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression on KMeans and PCA ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe_lin_reg = Pipeline([\n",
    "    (\"pca\", PCA(n_components=3)),\n",
    "    (\"ssc\", StandardScaler()),\n",
    "    (\"kmeans\", KMeans()),\n",
    "    (\"lin_reg\", LinearRegression())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    \"pca__n_components\" : np.arange(10),\n",
    "    \"kmeans__n_clusters\" : np.arange(10, 150, 10),\n",
    "    \"kmeans__max_iter\" : np.arange(500, 800, 100),\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(pipe_lin_reg, params, n_jobs=-1, cv=10)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {clf.best_params_}\")\n",
    "print(f\"Best training-score: {clf.best_score_:.3f}\")\n",
    "print(f\"Score on test data: {clf.score(X_test, y_test):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two turns with the above classifier result in: <br>\n",
    "<br>\n",
    "1m 33,8s<br>\n",
    "Best parameters: {'kmeans__max_iter': 600, 'kmeans__n_clusters': 60, 'pca__n_components': 8}<br>\n",
    "Best training-score: 0.577<br>\n",
    "Score on test data: 0.581<br>\n",
    "<br>\n",
    "1m 31.7s<br>\n",
    "Best parameters: {'kmeans__max_iter': 500, 'kmeans__n_clusters': 90, 'pca__n_components': 8}<br>\n",
    "Best training-score: 0.575<br>\n",
    "Score on test data: 0.582<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further possible improvements of Lin-Reg: ###\n",
    "\n",
    "1. use PolynomialFeatures instead of/ in addition to KMeans\n",
    "2. use regularization: non-negative least squares, ridge, lasso, elastic-net\n",
    "3. use Bayesian Regression (to chose a different type of regression from scikit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVR does not profit from KMeans: ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'kmeans__max_iter': 500, 'kmeans__n_clusters': 190}\n",
      "Best training-score: 0.436\n",
      "Score on test data: 0.438\n"
     ]
    }
   ],
   "source": [
    "pipe_svr = Pipeline([\n",
    "    (\"ssc\", StandardScaler()),\n",
    "    (\"kmeans\", KMeans()),\n",
    "    (\"svr\", SVR())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    \"kmeans__n_clusters\" : np.arange(10, 200, 10),\n",
    "    \"kmeans__max_iter\" : np.arange(500, 1000, 100),\n",
    "}\n",
    "clf = GridSearchCV(pipe_svr, params, n_jobs=-1, cv=10)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {clf.best_params_}\")\n",
    "print(f\"Best training-score: {clf.best_score_:.3f}\")\n",
    "print(f\"Score on test data: {clf.score(X_test, y_test):.3f}\")\n",
    "\n",
    "# Result:\n",
    "# Best parameters: {'kmeans__max_iter': 500, 'kmeans__n_clusters': 190}\n",
    "# Best training-score: 0.436\n",
    "# Score on test data: 0.438"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression with different Kernels ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator: Pipeline(steps=[('pca', PCA(n_components=8)), ('ssc', StandardScaler()),\n",
      "                ('svr', SVR())])\n",
      "Best parameter training: {'pca__n_components': 8}\n",
      "Score on testset: 0.554\n"
     ]
    }
   ],
   "source": [
    "# if kernel=None then by default kernel=\"rbf\" is used (see: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html)\n",
    "# We try polynomial features.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "pipe_svr = Pipeline([\n",
    "    (\"pca\", PCA()),\n",
    "    (\"ssc\", StandardScaler()),\n",
    "    #(\"svr\", SVR(kernel='poly')),\n",
    "    #(\"svr\", SVR(kernel='sigmoid')),\n",
    "    (\"svr\", SVR())\n",
    "\n",
    "])\n",
    "\n",
    "params = {\n",
    "    \"pca__n_components\" : np.arange(1,11),\n",
    "    #\"svr__degree\" : np.arange(2,6),\n",
    "}\n",
    "\n",
    "svr_clf = GridSearchCV(pipe_svr, params, n_jobs=-1, cv=10)\n",
    "\n",
    "svr_clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best estimator: {svr_clf.best_estimator_}\")\n",
    "print(f\"Best parameter training: {svr_clf.best_params_}\")\n",
    "print(f\"Score on testset: {svr_clf.score(X_test, y_test):.3f}\")\n",
    "\n",
    "# Results:\n",
    "# 1.\n",
    "# Best estimator: Pipeline(steps=[('ssc', StandardScaler()), ('svr', SVR(kernel='poly'))])\n",
    "# Best parameter training: {'svr__degree': 3}\n",
    "# Score on testset: 0.495\n",
    "#\n",
    "# 2.\n",
    "# Best estimator: Pipeline(steps=[('pca', PCA(n_components=5)), ('ssc', StandardScaler()),\n",
    "                #('svr', SVR(kernel='poly'))])\n",
    "# Best parameter training: {'pca__n_components': 5, 'svr__degree': 3}\n",
    "# Score on testset: 0.468\n",
    "#\n",
    "# 3.\n",
    "# Best estimator: Pipeline(steps=[('pca', PCA(n_components=10)), ('ssc', StandardScaler()),\n",
    "#                ('svr', SVR(kernel='sigmoid'))])\n",
    "# Best parameter training: {'pca__n_components': 10}\n",
    "# Score on testset: -44.512\n",
    "#\n",
    "# 4.\n",
    "# Best estimator: Pipeline(steps=[('pca', PCA(n_components=8)), ('ssc', StandardScaler()),\n",
    "#                ('svr', SVR())])\n",
    "# Best parameter training: {'pca__n_components': 8}\n",
    "# Score on testset: 0.554"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling Lin-Reg and SVR ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging Linear-Regression ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score bag-lin-regressor: 0.557\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "\n",
    "pipe_lin_reg = Pipeline([\n",
    "    (\"pca\", PCA(n_components=8)),\n",
    "    (\"ssc\", StandardScaler()),\n",
    "    (\"kmeans\", KMeans()),\n",
    "    (\"log_reg\", LinearRegression())\n",
    "])\n",
    "\n",
    "bag_lin_reg = BaggingRegressor(base_estimator=pipe_lin_reg, n_jobs=-1, n_estimators=10)\n",
    "bag_lin_reg.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Test score bag-lin-regressor: {bag_lin_reg.score(X_test, y_test):.3f}\")\n",
    "\n",
    "# Result:\n",
    "# Test score bag-lin-regressor: 0.557\n",
    "# similar results for n_estimators = 50, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    \"pca__n_components\" : np.arange(10),\n",
    "    \"kmeans__n_clusters\" : np.arange(10, 150, 10),\n",
    "    \"kmeans__max_iter\" : np.arange(500, 800, 100),\n",
    "}\n",
    "\n",
    "#clf = GridSearchCV(pipe_lin_reg, params, n_jobs=-1, cv=10)\n",
    "\n",
    "#clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {clf.best_params_}\")\n",
    "print(f\"Best training-score: {clf.best_score_:.3f}\")\n",
    "print(f\"Score on test data: {clf.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging Support Vector Regression ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score bag-regressor: 0.553\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "\n",
    "pipe_svr = Pipeline([\n",
    "    (\"pca\", PCA(n_components=8)),\n",
    "    (\"ssc\", StandardScaler()),\n",
    "    (\"svr\", SVR())\n",
    "])\n",
    "\n",
    "bag_svr = BaggingRegressor(base_estimator=pipe_svr, n_jobs=-1)\n",
    "bag_svr.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Test score bag-sv-regressor: {bag_svr.score(X_test, y_test):.3f}\")\n",
    "\n",
    "# Result:\n",
    "# 1.\n",
    "# n_estimators = 10\n",
    "# Test score bag-sv-regressor: 0.555\n",
    "# similar results with n_estimators = 30, 50, 100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sum-Up of BaggingRegressor application: ####\n",
    "Bagging did not improve lin-reg or svr. <br>\n",
    "Suspiciously the scores of bagging lin-reg and svr are almost equal: there might be a mistake in my implementation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling by Voting: Lin-Reg and SVR ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting-Regressor score: 0.578\n",
      "Voting estimators: [Pipeline(steps=[('pca', PCA(n_components=8)), ('ssc', StandardScaler()),\n",
      "                ('kmeans', KMeans(max_iter=600, n_clusters=60)),\n",
      "                ('log_reg', LinearRegression())]), Pipeline(steps=[('pca', PCA(n_components=8)), ('ssc', StandardScaler()),\n",
      "                ('svr', SVR())])]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "pipe_lin_reg = Pipeline([\n",
    "    (\"pca\", PCA(n_components=8)),\n",
    "    (\"ssc\", StandardScaler()),\n",
    "    (\"kmeans\", KMeans(max_iter=600, n_clusters= 60)),\n",
    "    (\"log_reg\", LinearRegression())\n",
    "])\n",
    "\n",
    "pipe_svr = Pipeline([\n",
    "    (\"pca\", PCA(n_components=8)),\n",
    "    (\"ssc\", StandardScaler()),\n",
    "    (\"svr\", SVR())\n",
    "])\n",
    "\n",
    "vr_reg = VotingRegressor([(\"lin_reg\", pipe_lin_reg), (\"svr\", pipe_svr)], n_jobs=-1)\n",
    "vr_reg.fit(X_train, y_train)\n",
    "print(f\"Voting-Regressor score: {vr_reg.score(X_test, y_test):.3f}\")\n",
    "print(f\"Voting estimators: {vr_reg.estimators_}\")\n",
    "\n",
    "# Result:\n",
    "# Voting-Regressor score: 0.578\n",
    "# Voting estimators: [Pipeline(steps=[('pca', PCA(n_components=8)), ('ssc', StandardScaler()),\n",
    "#                ('kmeans', KMeans(max_iter=600, n_clusters=60)),\n",
    "#                ('log_reg', LinearRegression())]), Pipeline(steps=[('pca', PCA(n_components=8)), ('ssc', StandardScaler()),\n",
    "#                ('svr', SVR())])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum-up Voting Regressor ###\n",
    "The voting-regressor consisting of a lin-reg and an svr does not do better than the lin-reg allone.\n",
    "<br>\n",
    "One reason might be, that both are doing well/not-so-well on the same sets of datapoints such that there is no gain in voting. <br> \n",
    "<br>\n",
    "Maybe we could improve by adding one of the weaker models to the ensemble (LogisticRegression, KNeighbourRegression, DecisionTreeRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model / Load Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk:\n",
    "import pickle\n",
    "\n",
    "filename = 'votingRegressor.sav'\n",
    "pickle.dump(vr_reg, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.578\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk: \n",
    "import pickle\n",
    "\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(f\"{result:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('condaPytorchEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df61620949cb14e55b843831dad5e2bfed0f7347786fc0c0d43a7e8bd69fd61c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
